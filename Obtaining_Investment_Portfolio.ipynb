{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Investment portfolio in Python ###\n",
    "## Obtaining the portfolio ##\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates # Required to style dates\n",
    "# Necessary for when working on notebooks\n",
    "# %matplotlib inline \n",
    "\n",
    "import datetime as dt # Used to define dates and time\n",
    "\n",
    "import time\n",
    "\n",
    "import yfinance as yf # Used to download stock information from Yahoo Finance\n",
    "import os # To work with directories and files in the operating system\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import cufflinks as cf # Library for connecting plotly with pandas\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "cf.go_offline()\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "#%%\n",
    "# Variable definition\n",
    "PATH = 'C:\\Users\\Felipe\\Desktop\\PortafoliodeInversionPython\\CSV\\Wilshire/'\n",
    "\n",
    "# Default start and end dates\n",
    "S_DATE = '2017-02-01'\n",
    "E_DATE = '2022-06-19'\n",
    "S_DATE_DT = pd.to_datetime(S_DATE)\n",
    "E_DATE_DT = pd.to_datetime(E_DATE)\n",
    "\n",
    "\n",
    "risk_free_rate = 0.0125 # Approximately the 10-year bond rate\n",
    "#%%\n",
    "# Getting the file names in a list\n",
    "\n",
    "files = [x for x in listdir(PATH) if isfile(join(PATH, x))]\n",
    "tickers = [os.path.splitext(x)[0] for x in files]\n",
    "tickers\n",
    "tickers.sort()\n",
    "len(tickers)\n",
    "\n",
    "#%%\n",
    "# Get the data from the created CSVs\n",
    "\n",
    "def get_stock_df_from_csv(ticker):\n",
    "    try:\n",
    "        df = pd.read_csv(PATH + ticker + '.csv', index_col=0)\n",
    "    except FileNotFoundError:\n",
    "        print('The file does not exists')\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "#%%\n",
    "# Join multiple actions by column name into a single df\n",
    "\n",
    "def merge_df_by_column_name(col_name, sdate, edate, *tickers):\n",
    "    # Will hold data for all dataframes with the same column name\n",
    "    mult_df = pd.DataFrame()\n",
    "    \n",
    "    for x in tickers:\n",
    "        df = get_stock_df_from_csv(x)\n",
    "        mask = (df.index >= sdate) & (df.index <= edate)\n",
    "        mult_df[x] = df.loc[mask][col_name]\n",
    "        \n",
    "    return mult_df\n",
    "\n",
    "#%%\n",
    "# Markowitz Portfolio Optimization\n",
    "\n",
    "\"\"\"\n",
    "Harry Markowitz proved that you could make what is called an efficient portfolio. That is a portfolio that optimizes return while also minimizing risk. We don't benefit from analyzing individual securities at the same rate as if we instead considered a portfolio of stocks.\n",
    "We do this by creating portfolios with stocks that are not correlated. We want to calculate expected returns by analyzing the returns of each stock multiplied by its weight.\n",
    "w1r1 + w2r2 = rp\n",
    "The standard deviation of the portfolio is found this way. Sum multiple calculations starting by finding the product of the first securities weight squared times its standard deviation squared. The middle is 2 times the correlation coefficient between the stocks. \n",
    "And, finally add those to the weight squared times the standard deviation squared for the second security.\n",
    "(w1d1 + w2d2)^2 = w1^2*d1^2 + 2w1d1w2d2 + w2^2 * d2^2\n",
    "\"\"\"\n",
    "\n",
    "# Draw the most efficient frontier\n",
    "# Selection of a portfolio with shares previously studied, with the data of the accumulated performance and Ishimoku\n",
    "# For that matter I selected some of specific sectors.\n",
    "\n",
    "port_list = ['PLUG', 'AMRC', 'GNRC',\n",
    "'HCC', 'RFP', 'CF',\n",
    "'IIPR', 'BRT', 'BRG',\n",
    "'CDNA', 'ZYXI', 'ARWR',\n",
    "'ATLC', 'KNSL', 'LPLA',\n",
    "'ENPH', 'APPS', 'SEDG',\n",
    "'RCMT', 'FCN', 'MHH',\n",
    "'NEE', 'MSEX', 'EXC',\n",
    "'TTGT', 'ROKU', 'IRDM',\n",
    "'OAS', 'VTNR', 'EGY']\n",
    "\n",
    "num_stocks = len(port_list)\n",
    "print(num_stocks)\n",
    "\n",
    "# Generate a df with the closing prices of all selected stocks\n",
    "\n",
    "mult_df = merge_df_by_column_name('Close', S_DATE, E_DATE, *port_list)\n",
    "\n",
    "#%%\n",
    "# Generate a chart for stock prices\n",
    "\n",
    "fig = px.line(mult_df, x = mult_df.index, y = mult_df.columns)\n",
    "fig.update_layout(height=1000, width=1800, showlegend=True)\n",
    "fig.update_xaxes(title=\"Date\", rangeslider_visible=True)\n",
    "fig.update_yaxes(title=\"Price\")\n",
    "plot(fig)\n",
    "\n",
    "#%%\n",
    "# Generate a price transformation and chart\n",
    "\n",
    "mult_df_t = np.log10(mult_df)\n",
    "\n",
    "fig = px.line(mult_df_t, x = mult_df_t.index, y = mult_df_t.columns)\n",
    "fig.update_layout(height=1000, width=1800, showlegend=True)\n",
    "fig.update_xaxes(title=\"Date\", rangeslider_visible=True)\n",
    "fig.update_yaxes(title=\"Log10 Price\")\n",
    "plot(fig)\n",
    "\n",
    "#%%\n",
    "# Average returns for one year (252 business days)\n",
    "\n",
    "returns = np.log(mult_df / mult_df.shift(1))\n",
    "mean_ret = returns.mean()*252\n",
    "print(mean_ret)\n",
    "\n",
    "#%%\n",
    "# Calculation of the correlation of actions\n",
    "returns.corr()\n",
    "\n",
    "# Stock Correlation Chart\n",
    "# We want a portfolio with low correlation between stocks\n",
    "import seaborn as sns\n",
    "correlation_matrix = returns.corr(method='spearman')\n",
    "fig = sns.heatmap(correlation_matrix, annot=False)\n",
    "# fig.update_layout(height=1000, width=1800, showlegend=True)\n",
    "plt.show()\n",
    "\n",
    "#%%\n",
    "# Generation of random weights whose sum is one\n",
    "\n",
    "weights = np.random.random(num_stocks)\n",
    "weights /= np.sum(weights)  # weights = weights / np.sum(weights)\n",
    "print('Weights: ', weights)\n",
    "print('Total weight: ', np.sum(weights))\n",
    "\n",
    "# Calculation of the average annual return with the random weights\n",
    "print(np.sum(weights * returns.mean()) * 252)\n",
    "\n",
    "#%%\n",
    "# Volatility Calculation\n",
    "# Portfolio risk with current weights\n",
    "\n",
    "print(np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights))))\n",
    "\n",
    "#%%\n",
    "# Running a simulation of 10000 portfolios using a function\n",
    "\n",
    "p_ret = [] # Returns list\n",
    "p_vol = [] # Volatility list\n",
    "p_SR = [] # Sharpe Ratio list\n",
    "p_wt = [] # Weights per portfolio list\n",
    "\n",
    "\n",
    "for x in range(10000):\n",
    "    # Generate randoms weights\n",
    "    p_weights = np.random.random(num_stocks)\n",
    "    p_weights /= np.sum(p_weights)\n",
    "    \n",
    "    # Calculation of the return according to the weights\n",
    "    ret_1 = np.sum(p_weights * returns.mean()) * 252\n",
    "    p_ret.append(ret_1)\n",
    "    \n",
    "    # Volatility Calculation\n",
    "    vol_1 = np.sqrt(np.dot(p_weights.T, np.dot(returns.cov() * 252, p_weights)))\n",
    "    p_vol.append(vol_1)\n",
    "    \n",
    "    # Calculation of the Sharpe ratio\n",
    "    SR_1 = (ret_1 - risk_free_rate) / vol_1\n",
    "    p_SR.append(SR_1)\n",
    "    \n",
    "    # Store the weights for each portfolio\n",
    "    p_wt.append(p_weights)\n",
    "    \n",
    "# Convert to numpy arrays\n",
    "p_ret = np.array(p_ret)\n",
    "p_vol = np.array(p_vol)\n",
    "p_SR = np.array(p_SR)\n",
    "p_wt = np.array(p_wt)\n",
    "\n",
    "p_ret, p_vol, p_SR, p_wt\n",
    "\n",
    "#%%\n",
    "# Graph of the simulated portfolios or most efficient frontier\n",
    "ports = pd.DataFrame({'Returns': p_ret, 'Volatility': p_vol, })\n",
    "ports.plot(x='Volatility', y = 'Returns', kind = 'scatter', figsize = (19,9))\n",
    "\n",
    "#%%\n",
    "# Sharpe ratio\n",
    "\n",
    "\"\"\"\n",
    "People want to maximize returns while avoiding as much risk as possible. \n",
    "William Sharpe created the Sharpe Ratio to find the portfolio that provides the best return for the lowest amount of risk.\n",
    "As return increases so does the Sharpe Ratio, but as Standard Deviation increase the Sharpe Ration decreases.\n",
    "\"\"\"\n",
    "# Returns the index for the highest Sharpe Ratio\n",
    "SR_idx = np.argmax(p_SR)\n",
    "\n",
    "# Find the ideal weights for the portfolio in that index\n",
    "i = 0\n",
    "while i < num_stocks:\n",
    "    print(\"Stock : %s : %2.2f\" % (port_list[i], (p_wt[SR_idx][i] * 100)))\n",
    "    i += 1\n",
    "    \n",
    "# Find the volatility of that portfolio\n",
    "print(\"\\nVolatility :\", p_vol[SR_idx] * 100)\n",
    "      \n",
    "# Find the return on that portfolio\n",
    "print(\"Return :\", p_ret[SR_idx] * 100)\n",
    "\n",
    "# You can also take percentages less than one and bring them closer to one, then calculate the portfolio.\n",
    "# In situations in which the percentages are less than one, what can be done is to bring them closer to one or to an action, or directly discard them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
