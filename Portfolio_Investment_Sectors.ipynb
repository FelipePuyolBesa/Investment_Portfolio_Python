{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Investment portfolio in Python ###\n",
    "## Obtaining the sectors for the queried actions ##\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates # Required to style dates\n",
    "# Necessary for when working on notebooks\n",
    "# %matplotlib inline \n",
    "\n",
    "import datetime as dt # Used to define dates and time\n",
    "\n",
    "import time\n",
    "\n",
    "import yfinance as yf # Used to download stock information from Yahoo Finance\n",
    "import os # To work with directories and files in the operating system\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import cufflinks as cf # Library for connecting plotly with pandas\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "cf.go_offline()\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "#%%\n",
    "# Variable definition\n",
    "PATH = 'C:\\Users\\Felipe\\Desktop\\PortafoliodeInversionPython\\CSV\\Wilshire/'\n",
    "\n",
    "# Default start and end dates\n",
    "S_DATE = '2017-02-01'\n",
    "E_DATE = '2022-06-19'\n",
    "S_DATE_DT = pd.to_datetime(S_DATE)\n",
    "E_DATE_DT = pd.to_datetime(E_DATE)\n",
    "\n",
    "#%%\n",
    "# Get the data from the created CSVs\n",
    "\n",
    "def get_stock_df_from_csv(ticker):\n",
    "    try:\n",
    "        df = pd.read_csv(PATH + ticker + '.csv', index_col=0)\n",
    "    except FileNotFoundError:\n",
    "        print('The file does not exists')\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "#%%\n",
    "\n",
    "# Cloud color assignment function\n",
    "\n",
    "def get_fill_color(label):\n",
    "    if label >= 1:\n",
    "        return 'rgba(0,250,0,0.4)'\n",
    "    else:\n",
    "        return 'rgba(250,0,0,0.4)'\n",
    "\n",
    "# Function for the Ishimoku graph\n",
    "\n",
    "def get_Ichimoku(df):\n",
    "\n",
    "    candle = go.Candlestick(x=df.index, open=df['Open'],\n",
    "    high=df['High'], low=df[\"Low\"], close=df['Close'], name=\"Candlestick\")\n",
    "\n",
    "    df1 = df.copy()\n",
    "    fig = go.Figure()\n",
    "    df['label'] = np.where(df['SpanA'] > df['SpanB'], 1, 0)\n",
    "    df['group'] = df['label'].ne(df['label'].shift()).cumsum()\n",
    "\n",
    "    df = df.groupby('group')\n",
    "\n",
    "    dfs = []\n",
    "    for name, data in df:\n",
    "        dfs.append(data)\n",
    "\n",
    "    for df in dfs:\n",
    "        fig.add_traces(go.Scatter(x=df.index, y=df.SpanA,\n",
    "        line=dict(color='rgba(0,0,0,0)')))\n",
    "\n",
    "        fig.add_traces(go.Scatter(x=df.index, y=df.SpanB,\n",
    "        line=dict(color='rgba(0,0,0,0)'),\n",
    "        fill='tonexty',\n",
    "        fillcolor=get_fill_color(df['label'].iloc[0])))\n",
    "\n",
    "    baseline = go.Scatter(x=df1.index, y=df1['Baseline'], \n",
    "    line=dict(color='pink', width=2), name=\"Baseline\")\n",
    "\n",
    "    conversion = go.Scatter(x=df1.index, y=df1['Conversion'], \n",
    "    line=dict(color='black', width=1), name=\"Conversion\")\n",
    "\n",
    "    lagging = go.Scatter(x=df1.index, y=df1['Lagging'], \n",
    "    line=dict(color='purple', width=2), name=\"Lagging\")\n",
    "\n",
    "    span_a = go.Scatter(x=df1.index, y=df1['SpanA'], \n",
    "    line=dict(color='green', width=2, dash='dot'), name=\"Span A\")\n",
    "\n",
    "    span_b = go.Scatter(x=df1.index, y=df1['SpanB'], \n",
    "    line=dict(color='red', width=1, dash='dot'), name=\"Span B\")\n",
    "\n",
    "    fig.add_trace(candle)\n",
    "    fig.add_trace(baseline)\n",
    "    fig.add_trace(conversion)\n",
    "    fig.add_trace(lagging)\n",
    "    fig.add_trace(span_a)\n",
    "    fig.add_trace(span_b)\n",
    "    \n",
    "    fig.update_layout(height=1000, width=1800, showlegend=True)\n",
    "\n",
    "    plot(fig)\n",
    "    \n",
    "\n",
    "#%%\n",
    "    \n",
    "# Obtain sector information for the stocks that make up the Wilshire 5000\n",
    "# This information is in the file 'big_stock_sectors.csv'\n",
    "\n",
    "sec_df = pd.read_csv(r'C:\\Users\\Felipe\\Desktop\\PortafoliodeInversionPython\\CSV/big_stock_sectors.csv')\n",
    "\n",
    "# Separation in different DF of the actions by sector\n",
    "\n",
    "# Consultation of the sectors\n",
    "print(sec_df['Sector'].unique())\n",
    "\n",
    "\"\"\"\n",
    "['Healthcare' 'Materials' 'SPAC' 'Discretionary' 'Real Estate'\n",
    " 'Industrial' 'Financials' 'Information Technology' 'Industrials'\n",
    " 'Staples' 'Services' 'Utilities' 'Communication' 'Energy' nan]\n",
    "\"\"\"\n",
    "\n",
    "indus_df = sec_df.loc[sec_df['Sector'] == 'Industrial']\n",
    "health_df = sec_df.loc[sec_df['Sector'] == 'Healthcare']\n",
    "it_df = sec_df.loc[sec_df['Sector'] == 'Information Technology']\n",
    "comm_df = sec_df.loc[sec_df['Sector'] == 'Communication']\n",
    "staple_df = sec_df.loc[sec_df['Sector'] == 'Staples']\n",
    "discretion_df = sec_df.loc[sec_df['Sector'] == 'Discretionary']\n",
    "materials_df = sec_df.loc[sec_df['Sector'] == 'Materials']\n",
    "spac_df = sec_df.loc[sec_df['Sector'] == 'SPAC']\n",
    "real_estate_df = sec_df.loc[sec_df['Sector'] == 'Real Estate']\n",
    "financials_df = sec_df.loc[sec_df['Sector'] == 'Financials']\n",
    "industrials_df = sec_df.loc[sec_df['Sector'] == 'Industrials']\n",
    "services_df = sec_df.loc[sec_df['Sector'] == 'Services']\n",
    "utilities_df = sec_df.loc[sec_df['Sector'] == 'Utilities']\n",
    "energy_df = sec_df.loc[sec_df['Sector'] == 'Energy']\n",
    "\n",
    "\n",
    "#%%\n",
    "# Creation of a function to calculate the accumulated return for each of the actions\n",
    "\n",
    "def get_cum_ret_for_stocks(stock_df):\n",
    "    tickers = []\n",
    "    cum_rets = []\n",
    "\n",
    "    for index, row in stock_df.iterrows():\n",
    "        df = get_stock_df_from_csv(row['Ticker'])\n",
    "        if df is None:\n",
    "            pass\n",
    "        else:\n",
    "            tickers.append(row['Ticker'])\n",
    "            cum = df['cum_return'].iloc[-1]\n",
    "            cum_rets.append(cum)\n",
    "    return pd.DataFrame({'Ticker':tickers, 'CUM_RET':cum_rets})\n",
    "\n",
    "#%%\n",
    "# Application of the function to find the accumulated number of shares\n",
    "\n",
    "Healthcare = get_cum_ret_for_stocks(health_df)\n",
    "Materials = get_cum_ret_for_stocks(materials_df)\n",
    "SPAC = get_cum_ret_for_stocks(spac_df)\n",
    "Discretionary = get_cum_ret_for_stocks(discretion_df)\n",
    "Real_Estate = get_cum_ret_for_stocks(real_estate_df)\n",
    "Industrial = get_cum_ret_for_stocks(indus_df)\n",
    "Financials = get_cum_ret_for_stocks(financials_df)\n",
    "IT = get_cum_ret_for_stocks(it_df)\n",
    "Industrials = get_cum_ret_for_stocks(industrials_df)\n",
    "Staples = get_cum_ret_for_stocks(staple_df)\n",
    "Services = get_cum_ret_for_stocks(services_df)\n",
    "Utilities = get_cum_ret_for_stocks(utilities_df)\n",
    "Communication = get_cum_ret_for_stocks(comm_df)\n",
    "Energy = get_cum_ret_for_stocks(energy_df)\n",
    "\n",
    "#%%\n",
    "# Review by sector of the stocks with the highest cumulative return\n",
    "\n",
    "print('Top 10 Industrial')\n",
    "print(Industrial.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: PLUG, AMRC, GNRC\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_ind = get_stock_df_from_csv('AMRC')\n",
    "get_Ichimoku(df_ind)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Materials')\n",
    "print(Materials.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: HCC, RFP, CF\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_mat = get_stock_df_from_csv('HCC')\n",
    "get_Ichimoku(df_mat)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Discretionary')\n",
    "print(Discretionary.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: CELH, BOOT, VERU\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_Discretionary = get_stock_df_from_csv('CELH')\n",
    "get_Ichimoku(df_Discretionary)\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Real_Estate')\n",
    "print(Real_Estate.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: IIPR, BRT, BRG\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_Real_Estate = get_stock_df_from_csv('IIPR')\n",
    "get_Ichimoku(df_Real_Estate)\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Healthcare')\n",
    "print(Healthcare.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: CDNA, ZYXI, ARWR\n",
    "\n",
    "# Graph some of the actions to decide in which one could invest.\n",
    "df_Healthcare = get_stock_df_from_csv('ZYXI')\n",
    "get_Ichimoku(df_Healthcare)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Financials')\n",
    "print(Financials.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: ATLC, KNSL, LPLA\n",
    "\n",
    "# Graph some of the actions to decide in which one could invest.\n",
    "df_Financials = get_stock_df_from_csv('ATLC')\n",
    "get_Ichimoku(df_Financials)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 IT')\n",
    "print(IT.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: ENPH, APPS, SEDG\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_IT = get_stock_df_from_csv('ENPH')\n",
    "get_Ichimoku(df_IT)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Industrials')\n",
    "print(Industrials.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: CAR, BXC, PTSI\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_Industrials = get_stock_df_from_csv('CAR')\n",
    "get_Ichimoku(df_Industrials)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Staples')\n",
    "print(Staples.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: DAR, FRPT, SMPL\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_Staples = get_stock_df_from_csv('DAR')\n",
    "get_Ichimoku(df_Staples)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Services')\n",
    "print(Services.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: RCMT, FCN, MHH\n",
    "\n",
    "# Graph some of the actions to decide in which one could invest.\n",
    "df_Services = get_stock_df_from_csv('RCMT')\n",
    "get_Ichimoku(df_Services)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Utilities')\n",
    "print(Utilities.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: NEE, MSEX, EXC\n",
    "\n",
    "# Graph some of the actions to decide in which one could invest.\n",
    "df_Utilities = get_stock_df_from_csv('NEE')\n",
    "get_Ichimoku(df_Utilities)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Communication')\n",
    "print(Communication.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected by highest cumulative return: TTGT, ROKU, IRDM\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_Communication = get_stock_df_from_csv('TTGT')\n",
    "get_Ichimoku(df_Communication)\n",
    "\n",
    "###\n",
    "\n",
    "print('Top 10 Energy')\n",
    "print(Energy.sort_values(by=['CUM_RET'], ascending=False).head(10))\n",
    "\n",
    "# Stocks selected for highest cumulative return: OAS, VTNR, EGY\n",
    "\n",
    "# Graph some of the actions to decide which one could invest.\n",
    "df_Energy = get_stock_df_from_csv('OAS')\n",
    "get_Ichimoku(df_Energy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
